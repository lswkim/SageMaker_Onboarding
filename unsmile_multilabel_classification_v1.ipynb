{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Script with Supported Framework - HuggingFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = 'implementation-unsmile'\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session(default_bucket=bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "str(now)[:19].replace('-', '').replace(':', '').replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "now = str(now)[:19].replace('-', '').replace(':', '').replace(' ', '')\n",
    "\n",
    "model_list = ['beomi/KcELECTRA-base', 'beomi/kcbert-base', 'beomi/kcbert-large']\n",
    "model_name = 'beomi/kcbert-base'\n",
    "\n",
    "num_train_epochs = 20\n",
    "per_device_train_batch_size = 16\n",
    "data_preprocessed = 'preprocessed'\n",
    "\n",
    "prefix = f'{now}_{model_name.split(\"/\")[1]}_{num_train_epochs}_{data_preprocessed}'\n",
    "\n",
    "output_path = \"s3://{}/{}/output\".format(bucket, prefix)\n",
    "checkpoint_url = \"s3://{}/{}/checkpoints\".format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters = {\n",
    "    'num_train_epochs': num_train_epochs, # train epochs\n",
    "    'per_device_train_batch_size': per_device_train_batch_size, # batch size\n",
    "    'model_name': model_name # model which will be trained on\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "huggingface_estimator = HuggingFace(\n",
    "        entry_point='train.py',\n",
    "        source_dir='./scripts',\n",
    "        instance_type='ml.g4dn.xlarge',\n",
    "        instance_count=1,\n",
    "        role=role,\n",
    "        transformers_version='4.12',\n",
    "        pytorch_version='1.9',\n",
    "        py_version='py38',\n",
    "        output_dir=output_path,\n",
    "        checkpoint_s3_uri=checkpoint_url,\n",
    "        hyperparameters=hyperparameters,\n",
    "        sagemaker_session=sess,\n",
    "        use_spot_instances=True,\n",
    "        max_wait=360000,\n",
    "        max_run=100000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Deploy process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = huggingface_estimator.deploy(1,\"ml.m5.large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def pre_processing(text):\n",
    "    text = re.sub('[^ㄱ-힣a-zA-Z0-9 ]', ' ', text)    \n",
    "    text = re.sub(' +', ' ', text)\n",
    "    \n",
    "    result_text = text[0]\n",
    "    cnt = 0\n",
    "    \n",
    "    for alpha in text[1:]:\n",
    "        if result_text[-1] == alpha: cnt += 1\n",
    "        else: cnt = 0\n",
    "\n",
    "        if cnt < 3: result_text += alpha\n",
    "        else: continue\n",
    "        \n",
    "    return result_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = '급식충아 꺼져!'\n",
    "inputs = pre_processing(inputs)\n",
    "\n",
    "sentiment_input= {\"inputs\": inputs}\n",
    "predictor2.predict(sentiment_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "import sagemaker \n",
    "\n",
    "# Load from s3 artifact\n",
    "role = sagemaker.get_execution_role()\n",
    "model_data = 's3://implementation-unsmile/huggingface-pytorch-training-2022-05-26-02-22-36-270/output/model.tar.gz'\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data=model_data, # path to your trained sagemaker model\n",
    "   role=role, # iam role with permissions to create an Endpoint\n",
    "   transformers_version=\"4.12\", # transformers version used\n",
    "   pytorch_version=\"1.9\", # pytorch version used\n",
    "   py_version=\"py38\", # python version of the DLC\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "   initial_instance_count=1,\n",
    "   instance_type=\"ml.m5.large\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example request, you always need to define \"inputs\"\n",
    "data = {\n",
    "   \"inputs\": \"조용히해!!!\"\n",
    "}\n",
    "\n",
    "# request\n",
    "predictor.predict(data)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.10 Python 3.8 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-northeast-2:806072073708:image/pytorch-1.10-cpu-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
